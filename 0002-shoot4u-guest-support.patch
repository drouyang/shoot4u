From 514e038373c79eede5bc60335a9125c56a0f7f82 Mon Sep 17 00:00:00 2001
From: Jiannan Ouyang <jiannan.ouyang@gmail.com>
Date: Thu, 16 Jul 2015 14:12:42 -0700
Subject: [PATCH 2/2] shoot4u guest support

---
 arch/x86/Kconfig                |  6 ++++++
 arch/x86/include/asm/tlbflush.h | 11 +++++++++++
 arch/x86/kernel/kvm.c           |  4 ++++
 arch/x86/mm/tlb.c               | 22 ++++++++++++++++++++++
 4 files changed, 43 insertions(+)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index b7d31ca..1ac7707 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -671,6 +671,12 @@ config PARAVIRT_SPINLOCKS
 
 	  If you are unsure how to answer this question, answer Y.
 
+config SHOOT4U
+	bool "Paravirt TLB shoot down"
+	depends on PARAVIRT && SMP
+	---help---
+	  If you are unsure how to answer this question, answer N.
+
 source "arch/x86/xen/Kconfig"
 
 config KVM_GUEST
diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h
index cd79194..07c7e2c 100644
--- a/arch/x86/include/asm/tlbflush.h
+++ b/arch/x86/include/asm/tlbflush.h
@@ -209,6 +209,13 @@ static inline void flush_tlb_mm_range(struct mm_struct *mm,
 		__flush_tlb_up();
 }
 
+static inline void shoot4u_flush_tlb_others(const struct cpumask *cpumask,
+					   struct mm_struct *mm,
+					   unsigned long start,
+					   unsigned long end)
+{
+}
+
 static inline void native_flush_tlb_others(const struct cpumask *cpumask,
 					   struct mm_struct *mm,
 					   unsigned long start,
@@ -246,6 +253,10 @@ extern void flush_tlb_kernel_range(unsigned long start, unsigned long end);
 
 #define flush_tlb()	flush_tlb_current_task()
 
+void shoot4u_flush_tlb_others(const struct cpumask *cpumask,
+				struct mm_struct *mm,
+				unsigned long start, unsigned long end);
+
 void native_flush_tlb_others(const struct cpumask *cpumask,
 				struct mm_struct *mm,
 				unsigned long start, unsigned long end);
diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c
index e354cc6..04acc4c 100644
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@ -295,6 +295,10 @@ static void __init paravirt_ops_setup(void)
 	if (kvm_para_has_feature(KVM_FEATURE_NOP_IO_DELAY))
 		pv_cpu_ops.io_delay = kvm_io_delay;
 
+#ifdef CONFIG_SHOOT4U
+        pv_mmu_ops.flush_tlb_others = shoot4u_flush_tlb_others;
+#endif
+
 #ifdef CONFIG_X86_IO_APIC
 	no_timer_check = 1;
 #endif
diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c
index 3250f23..3e6b553 100644
--- a/arch/x86/mm/tlb.c
+++ b/arch/x86/mm/tlb.c
@@ -12,7 +12,9 @@
 #include <asm/cache.h>
 #include <asm/apic.h>
 #include <asm/uv/uv.h>
+#include <asm/bitops.h>
 #include <linux/debugfs.h>
+#include <linux/kvm_para.h>
 
 /*
  *	Smarter SMP flushing macros.
@@ -130,6 +132,26 @@ static void flush_tlb_func(void *info)
 
 }
 
+void shoot4u_flush_tlb_others(const struct cpumask *cpumask,
+				 struct mm_struct *mm, unsigned long start,
+				 unsigned long end)
+{
+        // shoot4u currently uses a 8 bytes bitmap to pass target cores
+        // thus it supports up to 64 physical cores
+        u64 cpu_bitmap = 0;
+        int cpu;
+
+        for_each_cpu(cpu, cpumask) {
+          if (cpu >= 64) {
+            panic("[shoot4u] ERROR: do not support more than 64 cores\n");
+          }
+          set_bit(cpu, (void *)&cpu_bitmap);
+        }
+
+        printk("[shoot4u] before KVM_HC_SHOOT4U hypercall, cpumask: %llx, start %lx, end %lx\n", cpu_bitmap, start, end);
+        kvm_hypercall3(KVM_HC_SHOOT4U, cpu_bitmap, start, end);
+}
+
 void native_flush_tlb_others(const struct cpumask *cpumask,
 				 struct mm_struct *mm, unsigned long start,
 				 unsigned long end)
-- 
1.9.1

